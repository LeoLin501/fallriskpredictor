# -*- coding: utf-8 -*-
import pandas as pd
import numpy as np
import shap
import matplotlib.pyplot as plt
import seaborn as sns
import streamlit as st

from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
from xgboost import XGBClassifier
try:
    from lightgbm import LGBMClassifier
except ImportError:
    LGBMClassifier = None
from sklearn.ensemble import RandomForestClassifier

from imblearn.over_sampling import SMOTE
from io import BytesIO

# è¨­å®šä¸­æ–‡å­—é«”
plt.rcParams['font.family'] = 'Microsoft JhengHei'

# Streamlit é é¢è¨­å®š
st.set_page_config(page_title="å‡ç´šç‰ˆ AI è·Œå€’é¢¨éšªé æ¸¬", layout="wide")
st.title("ğŸ§  å‡ç´šç‰ˆ AI è·Œå€’é¢¨éšªé æ¸¬å¹³å°")

# Sidebar æ­¥é©Ÿ1
st.sidebar.header("æ­¥é©Ÿ 1ï¼šä¸Šå‚³ Excel")
uploaded_file = st.sidebar.file_uploader("è«‹é¸æ“‡åŒ…å«é æ¸¬æ¬„ä½èˆ‡è·Œå€’æ¨™ç±¤çš„ Excel æª”æ¡ˆ", type=[".xlsx"])

# é¢¨éšªåˆ†æ•¸æ˜ å°„è¡¨
risk_score_mapping = {
    "åˆ©å°¿åŠ‘": 3,
    "éº»é†‰æ­¢ç—›åŠ‘": 3,
    "ç·©ç€‰åŠ‘": 2,
    "é®éœå®‰çœ è—¥": 3,
    "é™è¡€å£“è—¥": 2,
    "é™è¡€ç³–è—¥": 2,
    "æŠ—çµ„ç¹”èƒº": 1,
    "è‚Œè‚‰é¬†å¼›åŠ‘": 3,
    "æŠ—æ†‚é¬±åŠ‘": 3
}

# è¡›æ•™å»ºè­°æ˜ å°„è¡¨
risk_education_mapping = {
    "è¡Œå‹•åŠ›": "åŠ å¼·å¹³è¡¡èˆ‡ä¸‹è‚¢è‚ŒåŠ›è¨“ç·´ï¼Œå®‰æ’å¾©å¥èª²ç¨‹ï¼Œä½¿ç”¨åˆé©çš„è¼”å…·ã€‚",
    "è·Œå€’å²": "æª¢è¦–å±…å®¶èˆ‡é†«é™¢ç’°å¢ƒï¼Œç§»é™¤éšœç¤™ç‰©ï¼Œé‹ªè¨­é˜²æ»‘åœ°å¢Šï¼Œå®šæœŸæª¢è¨è·Œå€’äº‹ä»¶ã€‚",
    "è—¥ç‰©é¢¨éšªåˆ†æ•¸": "è«‹è—¥å¸«é€²è¡Œè—¥ç‰©æ•´åˆè©•ä¼°ï¼Œé¿å…å¤šé‡é®éœã€é™å£“ã€åˆ©å°¿ç­‰é«˜é¢¨éšªè—¥ç‰©äº¤äº’ä½œç”¨ã€‚",
    "èªçŸ¥åˆ†é¡_è¼•åº¦éšœç¤™": "åŠ å¼·ç”¨è—¥å®‰å…¨æé†’ï¼Œæ¨™ç¤ºæ¸…æ¥šè—¥ç›’ï¼Œå®‰æ’é™ªä¼´å”åŠ©æ—¥å¸¸æ´»å‹•ã€‚",
    "èªçŸ¥åˆ†é¡_é‡åº¦éšœç¤™": "å®‰æ’ 24 å°æ™‚ç…§è­·æˆ–å®‰å…¨çœ‹è­·ï¼Œè¨­ç½®åºŠé‚Šè­·æ¬„ï¼Œé¿å…å–®ç¨è¡Œå‹•ã€‚",
    "æ˜¯å¦ç¨å±…": "å»ºè­°èˆ‡å®¶å±¬ã€ç¤¾å€è³‡æºè¯ç¹«ï¼Œå®‰æ’é™ªä¼´ï¼Œå®‰è£ç·Šæ€¥å‘¼å«ç³»çµ±ã€‚",
    "æ˜¯å¦æœ‰å®¶å±¬é™ªåŒ": "é¼“å‹µå®¶å±¬å­¸ç¿’ç…§è­·æŠ€å·§ï¼Œå…±åŒåƒèˆ‡ç—…äººè·Œå€’é é˜²æ•™è‚²ã€‚",
    "æ†‚é¬±ç—‡è¨ºæ–·": "è©•ä¼°å¿ƒç†ç‹€æ…‹ï¼Œæä¾›å¿ƒç†æ”¯æŒæˆ–è½‰ä»‹å¿ƒç†è«®å•†ï¼Œä¿ƒé€²æ­£å‘ç”Ÿæ´»å‹æ…‹ã€‚",
    "æ…¢æ€§ç–¾ç—…æ•¸é‡": "åŠ å¼·æ…¢ç—…ç®¡ç†ï¼Œå®‰æ’å®šæœŸå›è¨ºï¼Œæ³¨æ„ç–¾ç—…å°è¡Œå‹•åŠ›èˆ‡èªçŸ¥çš„å½±éŸ¿ã€‚",
    "ç’°å¢ƒé¢¨éšªåˆ†æ•¸": "æ”¹å–„å±…å®¶èˆ‡é†«ç™‚ç’°å¢ƒå®‰å…¨ï¼Œå¦‚è‰¯å¥½ç…§æ˜ã€æ‰¶æ‰‹è¨­ç½®ã€é˜²æ»‘è¨­æ–½ã€‚",
    "å¹´é½¡": "åŠ å¼·å¹´åº¦è·Œå€’é¢¨éšªç¯©æª¢ï¼Œé¼“å‹µå®šæœŸå¥åº·æª¢æŸ¥èˆ‡åŠŸèƒ½è©•ä¼°ã€‚",
    "æ€§åˆ¥": "é‡å°å¥³æ€§ç—…äººç‰¹åˆ¥æ³¨æ„éª¨è³ªç–é¬†ã€ç‡Ÿé¤Šè£œå……ï¼Œç”·æ€§å‰‡æ³¨æ„å¿ƒè¡€ç®¡é¢¨éšªèˆ‡æ´»å‹•å®‰å…¨ã€‚"
}


# é¢¨éšªåˆ†é¡å‡½æ•¸
def create_categorize_risk_fn(high, medium):
    def categorize_risk(prob):
        if prob >= high:
            return "é«˜é¢¨éšª"
        elif prob >= medium:
            return "ä¸­é¢¨éšª"
        else:
            return "ä½é¢¨éšª"
    return categorize_risk

# ä¸»æµç¨‹
if uploaded_file:
    data = pd.read_excel(uploaded_file)
    st.subheader("ğŸ“‹ åŸå§‹è³‡æ–™é è¦½")
    st.dataframe(data.head())

    if "è·Œå€’" not in data.columns:
        st.error("æ‰¾ä¸åˆ° 'è·Œå€’' æ¬„ä½ã€‚è«‹ç¢ºèªè³‡æ–™æ­£ç¢ºã€‚")
    else:
        # ç‰¹å¾µè™•ç†
        data["æ€§åˆ¥"] = data["æ€§åˆ¥"].map({"ç”·": 1, "å¥³": 0})
        data["è·Œå€’å²"] = data["è·Œå€’å²"].astype(int)

        def cognitive_level(score):
            if score >= 24:
                return "å®Œæ•´"
            elif score >= 18:
                return "è¼•åº¦éšœç¤™"
            else:
                return "é‡åº¦éšœç¤™"

        data["èªçŸ¥åˆ†é¡"] = data["èªçŸ¥åˆ†æ•¸"].apply(cognitive_level)
        data = pd.get_dummies(data, columns=["èªçŸ¥åˆ†é¡"], drop_first=True)

        def calculate_drug_score(drugs):
            if pd.isna(drugs):
                return 0
            return sum([risk_score_mapping.get(d.strip(), 0) for d in str(drugs).split(",")])

        data["è—¥ç‰©é¢¨éšªåˆ†æ•¸"] = data["è—¥ç‰©"].apply(calculate_drug_score)

        for col in ["æ˜¯å¦ç¨å±…", "æ˜¯å¦æœ‰å®¶å±¬é™ªåŒ", "æ†‚é¬±ç—‡è¨ºæ–·", "æ…¢æ€§ç–¾ç—…æ•¸é‡", "ç’°å¢ƒé¢¨éšªåˆ†æ•¸"]:
            if col not in data.columns:
                data[col] = 0

        feature_cols = [
            "å¹´é½¡", "æ€§åˆ¥", "è¡Œå‹•åŠ›", "è—¥ç‰©é¢¨éšªåˆ†æ•¸", "è·Œå€’å²",
            "æ˜¯å¦ç¨å±…", "æ˜¯å¦æœ‰å®¶å±¬é™ªåŒ", "æ†‚é¬±ç—‡è¨ºæ–·", "æ…¢æ€§ç–¾ç—…æ•¸é‡", "ç’°å¢ƒé¢¨éšªåˆ†æ•¸"
        ] + [col for col in data.columns if col.startswith("èªçŸ¥åˆ†é¡_")]

        X = data[feature_cols]
        y = data["è·Œå€’"]

        # SMOTE å¹³è¡¡è³‡æ–™
        minority_class_count = X[y == 1].shape[0]
        safe_k = min(5, minority_class_count - 1) if minority_class_count > 1 else 1
        smote = SMOTE(random_state=42, k_neighbors=safe_k)

        X_resampled, y_resampled = smote.fit_resample(X, y)

        X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.25, random_state=42)

        # Sidebar æ­¥é©Ÿ2
        st.sidebar.header("æ­¥é©Ÿ 2ï¼šæ¨¡å‹åƒæ•¸è¨­å®š")
        model_choice = st.sidebar.selectbox("é¸æ“‡æ¨¡å‹", ("XGBoost", "Random Forest", "LightGBM" if LGBMClassifier else "Random Forest"))

        if st.sidebar.button("é–‹å§‹è¨“ç·´æ¨¡å‹"):
            # æ¨¡å‹é¸æ“‡
            if model_choice == "XGBoost":
                model = XGBClassifier(
                    use_label_encoder=False,
                    eval_metric='logloss',
                    random_state=42,
                    n_estimators=300,
                    learning_rate=0.05,
                    max_depth=6,
                    subsample=0.8,
                    colsample_bytree=0.8
                )
            elif model_choice == "Random Forest":
                model = RandomForestClassifier(class_weight='balanced', random_state=42, n_estimators=300, max_depth=10)
            else:
                model = LGBMClassifier(class_weight='balanced', random_state=42)

            # æ¨¡å‹è¨“ç·´
            model.fit(X_train, y_train)
            y_proba = model.predict_proba(X_test)[:, 1]
            y_pred = (y_proba > 0.5).astype(int)

            auc_score = roc_auc_score(y_test, y_proba)
            st.success(f"AUC åˆ†æ•¸ï¼š{auc_score:.2f}")

            # ROC æ›²ç·š
            st.subheader("ğŸ“‰ ROC æ›²ç·š")
            fpr, tpr, _ = roc_curve(y_test, y_proba)
            fig_roc, ax_roc = plt.subplots()
            ax_roc.plot(fpr, tpr, label=f"AUC = {auc_score:.2f}", color='darkorange')
            ax_roc.plot([0, 1], [0, 1], linestyle='--', color='gray')
            ax_roc.set_xlabel("False Positive Rate")
            ax_roc.set_ylabel("True Positive Rate")
            ax_roc.set_title("ROC Curve")
            ax_roc.legend(loc="lower right")
            st.pyplot(fig_roc)

            # æ··æ·†çŸ©é™£
            st.subheader("ğŸ“Š æ··æ·†çŸ©é™£")
            cm = confusion_matrix(y_test, y_pred)
            fig_cm, ax_cm = plt.subplots()
            sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", ax=ax_cm,
                        xticklabels=["ç„¡è·Œå€’", "è·Œå€’"],
                        yticklabels=["ç„¡è·Œå€’", "è·Œå€’"])
            ax_cm.set_xlabel("é æ¸¬")
            ax_cm.set_ylabel("å¯¦éš›")
            ax_cm.set_title("æ··æ·†çŸ©é™£")
            st.pyplot(fig_cm)

            st.subheader("ğŸ“Œ ç‰¹å¾µé‡è¦æ€§åœ–")

            if model_choice == "Random Forest":
                st.info("éš¨æ©Ÿæ£®æ— â†’ ä½¿ç”¨ model.feature_importances_ ç¹ªè£½ç‰¹å¾µé‡è¦æ€§ (SHAP ä¸ç›¸å®¹ RF)")
                importances = model.feature_importances_
                indices = np.argsort(importances)[::-1]
                plt.figure(figsize=(10, 6))
                plt.title("Feature Importances (Random Forest)")
                plt.bar(range(X_train.shape[1]), importances[indices])
                plt.xticks(range(X_train.shape[1]), X_train.columns[indices], rotation=90)
                plt.tight_layout()
                st.pyplot(plt.gcf())

            else:
                explainer = shap.Explainer(model)
                shap_values = explainer(X_test)

                st.info(f"{model_choice} â†’ ä½¿ç”¨ SHAP beeswarm å±•ç¤ºç‰¹å¾µé‡è¦æ€§")
                plt.figure()
                shap.plots.beeswarm(shap_values, max_display=10)
                fig_shap = plt.gcf()
                st.pyplot(fig_shap)

            # è¡›æ•™å»ºè­°
            st.subheader("ğŸ“ è¡›æ•™å»ºè­°")
            categorize_risk = create_categorize_risk_fn(0.75, 0.4)
            result_df = X_test.copy()
            result_df["å¯¦éš›"] = y_test.values
            result_df["é æ¸¬æ©Ÿç‡"] = y_proba
            result_df["é¢¨éšªç­‰ç´š"] = result_df["é æ¸¬æ©Ÿç‡"].apply(categorize_risk)


            # é€²éšè¡›æ•™å»ºè­°æ˜ å°„è¡¨ (ç§»åˆ°å‡½æ•¸å¤–éƒ¨)
            risk_education_mapping = {
                "è¡Œå‹•åŠ›": "åŠ å¼·å¹³è¡¡èˆ‡ä¸‹è‚¢è‚ŒåŠ›è¨“ç·´ï¼Œå®‰æ’å¾©å¥èª²ç¨‹ï¼Œä½¿ç”¨åˆé©çš„è¼”å…·ã€‚",
                "è·Œå€’å²": "æª¢è¦–å±…å®¶èˆ‡é†«é™¢ç’°å¢ƒï¼Œç§»é™¤éšœç¤™ç‰©ï¼Œé‹ªè¨­é˜²æ»‘åœ°å¢Šï¼Œå®šæœŸæª¢è¨è·Œå€’äº‹ä»¶ã€‚",
                "è—¥ç‰©é¢¨éšªåˆ†æ•¸": "è«‹è—¥å¸«é€²è¡Œè—¥ç‰©æ•´åˆè©•ä¼°ï¼Œé¿å…å¤šé‡é®éœã€é™å£“ã€åˆ©å°¿ç­‰é«˜é¢¨éšªè—¥ç‰©äº¤äº’ä½œç”¨ã€‚",
                "èªçŸ¥åˆ†é¡_è¼•åº¦éšœç¤™": "åŠ å¼·ç”¨è—¥å®‰å…¨æé†’ï¼Œæ¨™ç¤ºæ¸…æ¥šè—¥ç›’ï¼Œå®‰æ’é™ªä¼´å”åŠ©æ—¥å¸¸æ´»å‹•ã€‚",
                "èªçŸ¥åˆ†é¡_é‡åº¦éšœç¤™": "å®‰æ’ 24 å°æ™‚ç…§è­·æˆ–å®‰å…¨çœ‹è­·ï¼Œè¨­ç½®åºŠé‚Šè­·æ¬„ï¼Œé¿å…å–®ç¨è¡Œå‹•ã€‚",
                "æ˜¯å¦ç¨å±…": "å»ºè­°èˆ‡å®¶å±¬ã€ç¤¾å€è³‡æºè¯ç¹«ï¼Œå®‰æ’é™ªä¼´ï¼Œå®‰è£ç·Šæ€¥å‘¼å«ç³»çµ±ã€‚",
                "æ˜¯å¦æœ‰å®¶å±¬é™ªåŒ": "é¼“å‹µå®¶å±¬å­¸ç¿’ç…§è­·æŠ€å·§ï¼Œå…±åŒåƒèˆ‡ç—…äººè·Œå€’é é˜²æ•™è‚²ã€‚",
                "æ†‚é¬±ç—‡è¨ºæ–·": "è©•ä¼°å¿ƒç†ç‹€æ…‹ï¼Œæä¾›å¿ƒç†æ”¯æŒæˆ–è½‰ä»‹å¿ƒç†è«®å•†ï¼Œä¿ƒé€²æ­£å‘ç”Ÿæ´»å‹æ…‹ã€‚",
                "æ…¢æ€§ç–¾ç—…æ•¸é‡": "åŠ å¼·æ…¢ç—…ç®¡ç†ï¼Œå®‰æ’å®šæœŸå›è¨ºï¼Œæ³¨æ„ç–¾ç—…å°è¡Œå‹•åŠ›èˆ‡èªçŸ¥çš„å½±éŸ¿ã€‚",
                "ç’°å¢ƒé¢¨éšªåˆ†æ•¸": "æ”¹å–„å±…å®¶èˆ‡é†«ç™‚ç’°å¢ƒå®‰å…¨ï¼Œå¦‚è‰¯å¥½ç…§æ˜ã€æ‰¶æ‰‹è¨­ç½®ã€é˜²æ»‘è¨­æ–½ã€‚",
                "å¹´é½¡": "åŠ å¼·å¹´åº¦è·Œå€’é¢¨éšªç¯©æª¢ï¼Œé¼“å‹µå®šæœŸå¥åº·æª¢æŸ¥èˆ‡åŠŸèƒ½è©•ä¼°ã€‚",
                "æ€§åˆ¥": "é‡å°å¥³æ€§ç—…äººç‰¹åˆ¥æ³¨æ„éª¨è³ªç–é¬†ã€ç‡Ÿé¤Šè£œå……ï¼Œç”·æ€§å‰‡æ³¨æ„å¿ƒè¡€ç®¡é¢¨éšªèˆ‡æ´»å‹•å®‰å…¨ã€‚"
            }
            # é€²éšè¡›æ•™å»ºè­°æ˜ å°„è¡¨
            advanced_education_mapping = {
                ("è·Œå€’å²",
                 "é«˜é¢¨éšª"): "ï¼ˆé«˜é¢¨éšª + è·Œå€’å²ï¼‰è©²ç—…æ‚£æœ‰åè¦†è·Œå€’å²ï¼Œå»ºè­°ç«‹å³å…¨é¢æª¢è¦–ç’°å¢ƒèˆ‡ç”¨è—¥ï¼Œå•Ÿå‹•è·¨åœ˜éšŠç…§è­·ï¼Œä¸¦å®‰æ’å€‹åˆ¥åŒ–é˜²è·Œè¨“ç·´ã€‚",
                ("è·Œå€’å²", "ä¸­é¢¨éšª"): "ï¼ˆä¸­é¢¨éšª + è·Œå€’å²ï¼‰ç—…æ‚£æœ‰è·Œå€’å²ï¼Œéœ€åŠ å¼·å®¶å±¬è¡›æ•™èˆ‡å±…å®¶ç’°å¢ƒèª¿æ•´ï¼Œå»ºè­° 3 å€‹æœˆå…§è¿½è¹¤ã€‚",
                ("è·Œå€’å²", "ä½é¢¨éšª"): "ï¼ˆä½é¢¨éšª + è·Œå€’å²ï¼‰ç—…æ‚£æ›¾æœ‰è·Œå€’å²ï¼Œå„˜ç®¡ç›®å‰ä½é¢¨éšªï¼Œæ‡‰æé†’æŒçºŒç•™æ„è¡Œå‹•å®‰å…¨ã€‚",
                ("è¡Œå‹•åŠ›", "é«˜é¢¨éšª"): "ï¼ˆé«˜é¢¨éšª + è¡Œå‹•åŠ›å·®ï¼‰éœ€å®‰æ’å¾©å¥èˆ‡ç‰©ç†æ²»ç™‚ï¼Œä¸¦è€ƒæ…®ä½¿ç”¨æ­¥æ…‹è¼”å…·ï¼Œåš´å¯†ç›£æ§æ´»å‹•å®‰å…¨ã€‚",
                ("èªçŸ¥åˆ†é¡_é‡åº¦éšœç¤™", "é«˜é¢¨éšª"): "ï¼ˆé«˜é¢¨éšª + é‡åº¦èªçŸ¥éšœç¤™ï¼‰æ‡‰å®‰æ’ 24 å°æ™‚çœ‹è­·ï¼Œå¼·åŒ–ç’°å¢ƒä¿è­·æªæ–½ï¼Œé¿å…å–®ç¨è¡Œå‹•ï¼Œç…§è­·åœ˜éšŠæ‡‰å¯†åˆ‡åˆä½œã€‚"
            }


            # å®šç¾© get_suggestion å‡½æ•¸
            def get_suggestion(feature_name, risk_level):
                advanced_key = (feature_name, risk_level)
                if advanced_key in advanced_education_mapping:
                    return advanced_education_mapping[advanced_key]

                base_suggestion = risk_education_mapping.get(feature_name, "å»ºè­°ä¸€èˆ¬å¥åº·ä¿ƒé€²èˆ‡å®šæœŸè©•ä¼°")
                if risk_level == "é«˜é¢¨éšª":
                    return f"(é«˜é¢¨éšªé‡é»ä»‹å…¥) {base_suggestion} æ‡‰ç«‹å³èˆ‡ç…§è­·åœ˜éšŠè¨è«–åŠ å¼·ç›£æ¸¬æ–¹æ¡ˆï¼Œå®‰æ’å€‹åˆ¥åŒ–çš„é˜²è·Œæªæ–½ï¼Œå¿…è¦æ™‚å•Ÿå‹•è·¨å°ˆæ¥­ç…§è­·ã€‚"
                elif risk_level == "ä¸­é¢¨éšª":
                    return f"(ä¸­é¢¨éšªæŒçºŒç›£æ¸¬) {base_suggestion} å»ºè­°æ–¼æœªä¾† 3 å€‹æœˆå…§å®‰æ’è‡³å°‘ä¸€æ¬¡é˜²è·Œè©•ä¼°ï¼Œä¸¦èˆ‡å®¶å±¬å…±åŒæª¢è¦–å±…å®¶èˆ‡ç…§è­·ç’°å¢ƒï¼Œé é˜²é¢¨éšªæå‡ã€‚"
                else:
                    return f"(ä½é¢¨éšªå¥åº·ä¿ƒé€²) {base_suggestion} ç›®å‰å±¬ä½é¢¨éšªï¼Œæ‡‰ç¶­æŒè‰¯å¥½ç”Ÿæ´»å‹æ…‹ï¼Œå®šæœŸæª¢è¦–ç’°å¢ƒå®‰å…¨åŠåŠŸèƒ½ç‹€æ…‹ï¼Œé é˜²é¢¨éšªè®ŠåŒ–ã€‚"


            # å±•ç¤ºé«˜ã€ä¸­ã€ä½é¢¨éšª â†’ ç”¨ st.expander åˆ†å€
            export_edu_list = []
            for risk_level in ["é«˜é¢¨éšª", "ä¸­é¢¨éšª", "ä½é¢¨éšª"]:
                cases = result_df[result_df["é¢¨éšªç­‰ç´š"] == risk_level]
                if not cases.empty:
                    with st.expander(f"{risk_level} å€‹æ¡ˆ ({len(cases)})"):
                        for idx, row in cases.iterrows():
                            st.write(f"**å€‹æ¡ˆç·¨è™Ÿï¼š{idx}**")

                            if model_choice == "Random Forest":
                                # RF â†’ ç”¨ feature_importances_ æ’å‰3å
                                top_features_idx = np.argsort(model.feature_importances_)[::-1][:3]
                                top_features = X_train.columns[top_features_idx]
                                for feature_name in top_features:
                                    suggestion = get_suggestion(feature_name, risk_level)
                                    st.write(f"- é‡å°ã€{feature_name}ã€‘ï¼š{suggestion}")

                            else:
                                # XGB/LGB â†’ ç”¨ SHAP per-case
                                case_position = list(X_test.index).index(idx)
                                shap_values_case = shap_values[case_position]
                                top_features = np.argsort(np.abs(shap_values_case.values))[-3:][::-1]
                                for feature_idx in top_features:
                                    feature_name = X_test.columns[feature_idx]
                                    suggestion = get_suggestion(feature_name, risk_level)
                                    st.write(f"- é‡å°ã€{feature_name}ã€‘ï¼š{suggestion}")


            # ä¸‹è¼‰å ±è¡¨åŠŸèƒ½
            def to_excel(df):
                output = BytesIO()
                with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
                    df.to_excel(writer, index=False)
                output.seek(0)
                return output


            st.download_button("ä¸‹è¼‰çµæœ (å…¨éƒ¨)", data=to_excel(result_df), file_name="fall_risk_predictions.xlsx")
            high_risk_cases = result_df[result_df["é¢¨éšªç­‰ç´š"] == "é«˜é¢¨éšª"]
            st.download_button("ä¸‹è¼‰é«˜é¢¨éšªåå–®", data=to_excel(high_risk_cases), file_name="high_risk_cases.xlsx")

            if export_edu_list:
                df_edu = pd.DataFrame(export_edu_list)
                st.download_button("ä¸‹è¼‰å€‹æ¡ˆè¡›æ•™å»ºè­°å ±è¡¨", data=to_excel(df_edu), file_name="fall_risk_education.xlsx")
